{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential removal of links and resiliency testing\n",
    "\n",
    "- Disruption of a network by removal of links, based on:\n",
    "    + Sum of betweeness centrality of from and to nodes\n",
    "    + Link length\n",
    "    + Volume of commodity flow\n",
    "- Calculation of performance in terms of cost and unmet demand by re-running disrupted network \n",
    "- Plot link removal along x-axis and performance on y-axis, comparing networks of differing evenness. Dynamic report generated in an RMarkdown automatically from this Notebook.\n",
    "\n",
    "**Assumptions**\n",
    "\n",
    "- Working in a Python 3.x environment for this notebook\n",
    "    + Refer to the README in this repository for instructions on setup of all dependencies with `conda`\n",
    "- Access to ArcGIS license server if necessary \n",
    "\n",
    "*Reference*\n",
    "\n",
    "- [NetworkX Documentation](https://networkx.github.io/documentation/stable/tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import sqlalchemy \n",
    "import networkx as nx\n",
    "import os\n",
    "import pickle\n",
    "import momepy # for conversion from geopandas GeoDataFrame to networkX Graph\n",
    "\n",
    "import resiliency_disruptions\n",
    "\n",
    "# Uses Reference Scenario 1 as an example. Modify `scen_name` and `scen_path` for your scenario.\n",
    "scen_name = 'rs1_multi_commodity_supply_chain'\n",
    "\n",
    "scen_path = os.path.join(\"C:\\\\FTOT\\\\scenarios\\\\reference_scenarios\\\\\", scen_name)\n",
    "\n",
    "shp_path = os.path.join(scen_path, 'temp_networkx_shp_files')\n",
    "\n",
    "picklename = os.path.join(scen_path, 'BetweenessG.pickle')\n",
    "\n",
    "if not os.path.exists(shp_path):\n",
    "    print('Please modify the FTOT code using the `ftot_networkx.py` and `ftot_routing.py` scripts in this repository and run the scenario again.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in prepared betweeness centrality and road network graph data. \n",
    "# If these don't exist, the following steps will create them\n",
    "if os.path.exists(picklename):\n",
    "    file = open(picklename, 'rb')\n",
    "    betweenness_dict_road = pickle.load(file)\n",
    "    G_road = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by using betweeness centrality calculation using networkX\n",
    "if not os.path.exists(picklename):\n",
    "    road = gpd.read_file(os.path.join(shp_path, 'road.shp'))\n",
    "    \n",
    "    # convert from geodataframe to Graph for networkX\n",
    "    G_road = momepy.gdf_to_nx(road, approach='primal')\n",
    "    \n",
    "    # Process the networkX graph\n",
    "    G_road = nx.convert_node_labels_to_integers(G_road, first_label=0, ordering='default', label_attribute=\"xy_coord_label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run betweenness centrality on the NetworkX graph\n",
    "# Note: This step might take 20+ minutes\n",
    "# Run if pickle not available\n",
    "if not os.path.exists(picklename):\n",
    "    print('Running Betweeness Centrality calculations. This might take more than 20 minutes.')\n",
    "    betweenness_dict_road = nx.betweenness_centrality(G_road, normalized=False, weight='MILES')\n",
    "    print('Completed Betweeness Centrality calculations.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save with pickle\n",
    "# On load, need to know that there are two objects in this pickle, the betweeness centrality dict and the network G\n",
    "if not os.path.exists(picklename):\n",
    "    with open(picklename, 'wb') as handle:\n",
    "        pickle.dump(betweenness_dict_road, handle)\n",
    "        pickle.dump(G_road, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Betweeness Centrality calculations to edges \n",
    "\n",
    "- Sum BC for each node of a link\n",
    "- Create data frame for repeated link removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\FTOT\\scenarios\\reference_scenarios\\rs1_multi_commodity_supply_chain\n"
     ]
    }
   ],
   "source": [
    "# Read in FTOT data\n",
    "print(scen_path)\n",
    "db_name = 'main.db'\n",
    "\n",
    "db_path = 'sqlite:///' + os.path.join(scen_path, db_name)\n",
    "\n",
    "engine = sqlalchemy.create_engine(db_path)\n",
    "\n",
    "table_name = 'networkx_edges'\n",
    "nx_edges = pd.read_sql_table(table_name, engine)\n",
    "\n",
    "table_name = 'networkx_nodes'\n",
    "nx_nodes = pd.read_sql_table(table_name, engine)\n",
    "\n",
    "table_name = 'optimal_variables'\n",
    "optimal_vars = pd.read_sql_table(table_name, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_orig_label = gpd.read_file(os.path.join(shp_path, 'road.shp'))\n",
    "# convert from geodataframe to Graph for networkX\n",
    "G_road_orig_label = momepy.gdf_to_nx(road_orig_label, approach='primal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_orig_label_nodes = list(G_road_orig_label.nodes) # these values are the shape_x and shape_y values in `networkx_nodes`. \n",
    "# Use that to get node_id from networkx_edges in the database,\n",
    "# Then use those id values to get edges info\n",
    "# Then line up the new integer labels with this list of ids to get betweeness centrality for each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the betweeness_centrality values as the framework to join in shape_x, shape_y, and node_id\n",
    "bc_df_road = pd.DataFrame.from_dict(betweenness_dict_road, orient = 'index')\n",
    "bc_df_road = bc_df_road.rename(columns = {0: 'BC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_shape_df_road = pd.DataFrame(road_orig_label_nodes)\n",
    "\n",
    "bc_shape_df_road = pd.concat([bc_df_road, node_shape_df_road], axis = 1)\n",
    "bc_shape_df_road = bc_shape_df_road.rename(columns = {0: 'shape_x', 1: 'shape_y'})\n",
    "\n",
    "# Now add node_id from networkx_nodes, using pandas merge with left join.\n",
    "# Use both shape_x and shape_y to identify the nodes correctly\n",
    "# Union of both prod and crude now\n",
    "\n",
    "bc_node_df = pd.merge(bc_shape_df_road, nx_nodes, on = ['shape_x', 'shape_y'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use this data frame to populate a data frame of edges. \n",
    "# We will want the following from networkx_edges:\n",
    "# edge_id, from_node_id, to_node_id, mode_source, miles, mode_source_oid, \n",
    "# Then using the node_id column in the new bc_node_df, add these:\n",
    "# from_node_BC, to_node_BC\n",
    "# and sum those for sum_node_BC\n",
    "merge_from = pd.merge(nx_edges, bc_node_df[['BC','node_id']],\n",
    "                      left_on = 'from_node_id',\n",
    "                      right_on = 'node_id',\n",
    "                      how = 'left')\n",
    "merge_from = merge_from.rename(columns = {'BC': 'from_node_BC'})\n",
    "\n",
    "merge_to = pd.merge(merge_from, bc_node_df[['BC','node_id',]],\n",
    "                    left_on = 'to_node_id',\n",
    "                    right_on = 'node_id',\n",
    "                    how = 'left')\n",
    "merge_to = merge_to.rename(columns = {'BC': 'to_node_BC'})\n",
    "\n",
    "# Sum the BC values\n",
    "\n",
    "merge_to['sum_BC'] = merge_to.filter(like = \"node_BC\").sum(axis = 1)\n",
    "\n",
    "# Then from optimal_variables, get variable_name, nc_edge_id, mode, mode_oid, miles,\n",
    "# variable_value, converted_capacity, and converted_volume\n",
    "\n",
    "use_opt_vars = ['variable_type',\n",
    "               'var_id',\n",
    "               'variable_value',\n",
    "                'variable_name',\n",
    "                'nx_edge_id',\n",
    "                'mode_oid',\n",
    "                'converted_capacity',\n",
    "                'converted_volume'\n",
    "               ]\n",
    "\n",
    "merge_opt = pd.merge(merge_to, optimal_vars[use_opt_vars],\n",
    "                    left_on = 'edge_id',\n",
    "                    right_on = 'nx_edge_id',\n",
    "                    how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edge_id</th>\n",
       "      <th>from_node_id</th>\n",
       "      <th>to_node_id</th>\n",
       "      <th>artificial</th>\n",
       "      <th>mode_source</th>\n",
       "      <th>mode_source_oid</th>\n",
       "      <th>length</th>\n",
       "      <th>route_cost_scaling</th>\n",
       "      <th>capacity</th>\n",
       "      <th>volume</th>\n",
       "      <th>...</th>\n",
       "      <th>node_id_y</th>\n",
       "      <th>sum_BC</th>\n",
       "      <th>variable_type</th>\n",
       "      <th>var_id</th>\n",
       "      <th>variable_value</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>nx_edge_id</th>\n",
       "      <th>mode_oid</th>\n",
       "      <th>converted_capacity</th>\n",
       "      <th>converted_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2179</td>\n",
       "      <td>2</td>\n",
       "      <td>rail</td>\n",
       "      <td>178</td>\n",
       "      <td>0.013221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31672</td>\n",
       "      <td>2</td>\n",
       "      <td>water</td>\n",
       "      <td>1373</td>\n",
       "      <td>0.351856</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2180</td>\n",
       "      <td>2</td>\n",
       "      <td>rail</td>\n",
       "      <td>179</td>\n",
       "      <td>0.064799</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   edge_id  from_node_id  to_node_id  artificial mode_source  mode_source_oid  \\\n",
       "0        1             0        2179           2        rail              178   \n",
       "1        2             0       31672           2       water             1373   \n",
       "2        3             1        2180           2        rail              179   \n",
       "\n",
       "     length  route_cost_scaling  capacity  volume  ...  node_id_y  sum_BC  \\\n",
       "0  0.013221                 1.0       NaN     0.0  ...        NaN     0.0   \n",
       "1  0.351856                 1.0       NaN     NaN  ...        NaN     0.0   \n",
       "2  0.064799                 1.0       NaN     0.0  ...        NaN     0.0   \n",
       "\n",
       "   variable_type  var_id  variable_value  variable_name nx_edge_id  mode_oid  \\\n",
       "0            NaN     NaN             NaN            NaN        NaN       NaN   \n",
       "1            NaN     NaN             NaN            NaN        NaN       NaN   \n",
       "2            NaN     NaN             NaN            NaN        NaN       NaN   \n",
       "\n",
       "   converted_capacity converted_volume  \n",
       "0                 NaN              NaN  \n",
       "1                 NaN              NaN  \n",
       "2                 NaN              NaN  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_opt.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>edge_id</th>\n",
       "      <th>from_node_id</th>\n",
       "      <th>to_node_id</th>\n",
       "      <th>capacity</th>\n",
       "      <th>volume</th>\n",
       "      <th>sum_BC</th>\n",
       "      <th>variable_type</th>\n",
       "      <th>variable_value</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>nx_edge_id</th>\n",
       "      <th>mode_oid</th>\n",
       "      <th>converted_capacity</th>\n",
       "      <th>converted_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59863</td>\n",
       "      <td>59823</td>\n",
       "      <td>26838</td>\n",
       "      <td>25850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.269425e+07</td>\n",
       "      <td>Edge</td>\n",
       "      <td>90.718474</td>\n",
       "      <td>Edge_418617</td>\n",
       "      <td>59823.0</td>\n",
       "      <td>183601.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58587</td>\n",
       "      <td>58547</td>\n",
       "      <td>26223</td>\n",
       "      <td>26838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.051310e+07</td>\n",
       "      <td>Edge</td>\n",
       "      <td>90.718474</td>\n",
       "      <td>Edge_409685</td>\n",
       "      <td>58547.0</td>\n",
       "      <td>327587.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57885</td>\n",
       "      <td>57846</td>\n",
       "      <td>25850</td>\n",
       "      <td>26850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.520044e+06</td>\n",
       "      <td>Edge</td>\n",
       "      <td>90.718474</td>\n",
       "      <td>Edge_404778</td>\n",
       "      <td>57846.0</td>\n",
       "      <td>183613.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  edge_id  from_node_id  to_node_id  capacity  volume        sum_BC  \\\n",
       "0  59863    59823         26838       25850       NaN     0.0  1.269425e+07   \n",
       "1  58587    58547         26223       26838       NaN     0.0  1.051310e+07   \n",
       "2  57885    57846         25850       26850       NaN     0.0  9.520044e+06   \n",
       "\n",
       "  variable_type  variable_value variable_name  nx_edge_id  mode_oid  \\\n",
       "0          Edge       90.718474   Edge_418617     59823.0  183601.0   \n",
       "1          Edge       90.718474   Edge_409685     58547.0  327587.0   \n",
       "2          Edge       90.718474   Edge_404778     57846.0  183613.0   \n",
       "\n",
       "  converted_capacity  converted_volume  \n",
       "0               None               0.0  \n",
       "1               None               0.0  \n",
       "2               None               0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create ranked lists of edges to remove.\n",
    "# First, keep only edges in the optimal solution.\n",
    "# Then rank by sum_BC. Then just keep the columns we need, and reset the index.\n",
    "use_cols = ['edge_id', 'from_node_id', 'to_node_id', 'miles', 'capacity', 'volume', 'sum_BC',\n",
    "           'variable_type', 'variable_value', 'variable_name', 'nx_edge_id', 'mode_oid', 'converted_capacity', 'converted_volume']\n",
    "\n",
    "edges_remove = merge_opt[merge_opt['variable_value'] > 0].sort_values(by = 'sum_BC', ascending = False).filter(items = use_cols).reset_index()\n",
    "\n",
    "edges_remove.to_csv(os.path.join(scen_path, 'Edges_to_Remove.csv'),\n",
    "                   index = False)\n",
    "\n",
    "edges_remove.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Scenarios, Disrupt, Run FTOT\n",
    "\n",
    "Create disrupted network by copying everyhing in `scen_path` to a new directory\n",
    "\n",
    "Then overwrites the `networkx_edges` tables in that main.db, with the disrupted versions.\n",
    "\n",
    "##### Assuptions:\n",
    "\n",
    "  1. ArcGIS with 64-bit geoprocessing is installed\n",
    "  2. The FTOT version being used has been modified according to the `README` in this directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 25 scenarios based on rs1_multi_commodity_supply_chain\n"
     ]
    }
   ],
   "source": [
    "disrupt_type = 'BC' # Can disrupt basaed on betweeness centrality or volume, 'V'\n",
    "disrupt_steps = 25  # This is the number of steps to use. Recommend at least 25.\n",
    "\n",
    "resiliency_disruptions.make_disruption_scenarios(disrupt_type, disrupt_steps, scen_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disrupted 25 scenarios\n"
     ]
    }
   ],
   "source": [
    "resiliency_disruptions.disrupt_network(disrupt_type, disrupt_steps, scen_path, edges_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\FTOT\\program\\ftot.py\n"
     ]
    }
   ],
   "source": [
    "PYTHON = r\"C:\\FTOT\\python3_env\\python.exe\"\n",
    "repo_location = %pwd\n",
    "repo_location = os.path.split(repo_location)[0] \n",
    "FTOT = r\"C:\\FTOT\\program\\ftot.py\" # Optionally: os.path.join(repo_location, 'program', 'ftot.py')\n",
    "print(FTOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running o1 for disrupt01\n",
      "Running o2 for disrupt01\n",
      "Running p for disrupt01\n",
      "Running d for disrupt01\n",
      "Preparing to search over o2_log_2023_06_07_19-52-15.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           01    22.679618    113,398   470    120,444\n",
      "Running o1 for disrupt02\n",
      "Running o2 for disrupt02\n",
      "Running p for disrupt02\n",
      "Running d for disrupt02\n",
      "Preparing to search over o2_log_2023_06_07_19-58-22.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           02    22.679618    113,398   470    120,444\n",
      "Running o1 for disrupt03\n",
      "Running o2 for disrupt03\n",
      "Running p for disrupt03\n",
      "Running d for disrupt03\n",
      "Preparing to search over o2_log_2023_06_07_20-03-58.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           03    22.679618    113,398   470    120,444\n",
      "Running o1 for disrupt04\n",
      "Running o2 for disrupt04\n",
      "Running p for disrupt04\n",
      "Running d for disrupt04\n",
      "Preparing to search over o2_log_2023_06_07_20-09-15.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           04    22.679618    113,398   470    120,444\n",
      "Running o1 for disrupt05\n",
      "Running o2 for disrupt05\n",
      "Running p for disrupt05\n",
      "Running d for disrupt05\n",
      "Preparing to search over o2_log_2023_06_07_20-14-33.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           05    22.679618    113,398   470    120,444\n",
      "Running o1 for disrupt06\n",
      "Running o2 for disrupt06\n",
      "Running p for disrupt06\n",
      "Running d for disrupt06\n",
      "Preparing to search over o2_log_2023_06_07_20-19-45.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           06    22.679618    113,398   470    120,444\n",
      "Running o1 for disrupt07\n",
      "Running o2 for disrupt07\n",
      "Running p for disrupt07\n",
      "Running d for disrupt07\n",
      "Preparing to search over o2_log_2023_06_07_20-25-22.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           07    22.679618    113,398   476    120,461\n",
      "Running o1 for disrupt08\n",
      "Running o2 for disrupt08\n",
      "Running p for disrupt08\n",
      "Running d for disrupt08\n",
      "Preparing to search over o2_log_2023_06_07_20-31-04.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           08    22.679618    113,398   476    120,461\n",
      "Running o1 for disrupt09\n",
      "Running o2 for disrupt09\n",
      "Running p for disrupt09\n",
      "Running d for disrupt09\n",
      "Preparing to search over o2_log_2023_06_07_20-36-48.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           09    22.679618    113,398   476    120,461\n",
      "Running o1 for disrupt10\n",
      "Running o2 for disrupt10\n",
      "Running p for disrupt10\n",
      "Running d for disrupt10\n",
      "Preparing to search over o2_log_2023_06_07_20-42-28.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           10    22.679618    113,398   476    120,461\n",
      "Running o1 for disrupt11\n",
      "Running o2 for disrupt11\n",
      "Running p for disrupt11\n",
      "Running d for disrupt11\n",
      "Preparing to search over o2_log_2023_06_07_20-47-55.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           11    22.679618    113,398   464    120,465\n",
      "Running o1 for disrupt12\n",
      "Running o2 for disrupt12\n",
      "Running p for disrupt12\n",
      "Running d for disrupt12\n",
      "Preparing to search over o2_log_2023_06_07_20-53-37.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           12    22.679618    113,398   464    120,465\n",
      "Running o1 for disrupt13\n",
      "Running o2 for disrupt13\n",
      "Running p for disrupt13\n",
      "Running d for disrupt13\n",
      "Preparing to search over o2_log_2023_06_07_20-59-08.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           13    22.679618    113,398   464    120,465\n",
      "Running o1 for disrupt14\n",
      "Running o2 for disrupt14\n",
      "Running p for disrupt14\n",
      "Running d for disrupt14\n",
      "Preparing to search over o2_log_2023_06_07_21-04-26.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           14    22.679618    113,398   464    120,465\n",
      "Running o1 for disrupt15\n",
      "Running o2 for disrupt15\n",
      "Running p for disrupt15\n",
      "Running d for disrupt15\n",
      "Preparing to search over o2_log_2023_06_07_21-09-36.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           15    22.679618    113,398   464    120,465\n",
      "Running o1 for disrupt16\n",
      "Running o2 for disrupt16\n",
      "Running p for disrupt16\n",
      "Running d for disrupt16\n",
      "Preparing to search over o2_log_2023_06_07_21-15-03.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           16    22.679618    113,398   464    120,465\n",
      "Running o1 for disrupt17\n",
      "Running o2 for disrupt17\n",
      "Running p for disrupt17\n",
      "Running d for disrupt17\n",
      "Preparing to search over o2_log_2023_06_07_21-20-34.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           17    22.679618    113,398   464    120,465\n",
      "Running o1 for disrupt18\n",
      "Running o2 for disrupt18\n",
      "Running p for disrupt18\n",
      "Running d for disrupt18\n",
      "Preparing to search over o2_log_2023_06_07_21-25-42.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           18    22.679618    113,398   464    120,465\n",
      "Running o1 for disrupt19\n",
      "Running o2 for disrupt19\n",
      "Running p for disrupt19\n",
      "Running d for disrupt19\n",
      "Preparing to search over o2_log_2023_06_07_21-30-53.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           19    22.679618    113,398   464    120,465\n",
      "Running o1 for disrupt20\n",
      "Running o2 for disrupt20\n",
      "Running p for disrupt20\n",
      "Running d for disrupt20\n",
      "Preparing to search over o2_log_2023_06_07_21-36-44.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           20    22.679618    113,398   481    120,778\n",
      "Running o1 for disrupt21\n",
      "Running o2 for disrupt21\n",
      "Running p for disrupt21\n",
      "Running d for disrupt21\n",
      "Preparing to search over o2_log_2023_06_07_21-42-17.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           21    22.679618    113,398   481    120,778\n",
      "Running o1 for disrupt22\n",
      "Running o2 for disrupt22\n",
      "Running p for disrupt22\n",
      "Running d for disrupt22\n",
      "Preparing to search over o2_log_2023_06_07_21-47-27.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           22    22.679618    113,398   481    120,778\n",
      "Running o1 for disrupt23\n",
      "Running o2 for disrupt23\n",
      "Running p for disrupt23\n",
      "Running d for disrupt23\n",
      "Preparing to search over o2_log_2023_06_07_21-53-02.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           23    22.679618    113,398   481    120,778\n",
      "Running o1 for disrupt24\n",
      "Running o2 for disrupt24\n",
      "Running p for disrupt24\n",
      "Running d for disrupt24\n",
      "Preparing to search over o2_log_2023_06_07_21-58-12.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           24    22.679618    113,398   481    120,778\n",
      "Running o1 for disrupt25\n",
      "Running o2 for disrupt25\n",
      "Running p for disrupt25\n",
      "Running d for disrupt25\n",
      "Preparing to search over o2_log_2023_06_07_22-03-38.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           25    22.679618    113,398   478    120,779\n"
     ]
    }
   ],
   "source": [
    "# Begin running O steps of FTOT on the disupted scenarios\n",
    "# This may take several hours, depending on size of the network and number of steps\n",
    "\n",
    "results = resiliency_disruptions.run_o_steps(disrupt_type, disrupt_steps, scen_path, PYTHON, FTOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>disrupt_step</th>\n",
       "      <th>unmet_demand</th>\n",
       "      <th>unmet_cost</th>\n",
       "      <th>nedge</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>01</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>470</td>\n",
       "      <td>120,444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>02</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>470</td>\n",
       "      <td>120,444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>03</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>470</td>\n",
       "      <td>120,444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>04</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>470</td>\n",
       "      <td>120,444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>05</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>470</td>\n",
       "      <td>120,444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>06</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>470</td>\n",
       "      <td>120,444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>07</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>476</td>\n",
       "      <td>120,461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>08</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>476</td>\n",
       "      <td>120,461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>09</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>476</td>\n",
       "      <td>120,461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>476</td>\n",
       "      <td>120,461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>464</td>\n",
       "      <td>120,465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>464</td>\n",
       "      <td>120,465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>464</td>\n",
       "      <td>120,465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>464</td>\n",
       "      <td>120,465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>464</td>\n",
       "      <td>120,465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>464</td>\n",
       "      <td>120,465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>464</td>\n",
       "      <td>120,465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>464</td>\n",
       "      <td>120,465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>464</td>\n",
       "      <td>120,465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>481</td>\n",
       "      <td>120,778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>481</td>\n",
       "      <td>120,778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>481</td>\n",
       "      <td>120,778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>481</td>\n",
       "      <td>120,778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>481</td>\n",
       "      <td>120,778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>22.679618</td>\n",
       "      <td>113,398</td>\n",
       "      <td>478</td>\n",
       "      <td>120,779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index disrupt_step unmet_demand unmet_cost nedge total_cost\n",
       "0       0           01    22.679618    113,398   470    120,444\n",
       "1       0           02    22.679618    113,398   470    120,444\n",
       "2       0           03    22.679618    113,398   470    120,444\n",
       "3       0           04    22.679618    113,398   470    120,444\n",
       "4       0           05    22.679618    113,398   470    120,444\n",
       "5       0           06    22.679618    113,398   470    120,444\n",
       "6       0           07    22.679618    113,398   476    120,461\n",
       "7       0           08    22.679618    113,398   476    120,461\n",
       "8       0           09    22.679618    113,398   476    120,461\n",
       "9       0           10    22.679618    113,398   476    120,461\n",
       "10      0           11    22.679618    113,398   464    120,465\n",
       "11      0           12    22.679618    113,398   464    120,465\n",
       "12      0           13    22.679618    113,398   464    120,465\n",
       "13      0           14    22.679618    113,398   464    120,465\n",
       "14      0           15    22.679618    113,398   464    120,465\n",
       "15      0           16    22.679618    113,398   464    120,465\n",
       "16      0           17    22.679618    113,398   464    120,465\n",
       "17      0           18    22.679618    113,398   464    120,465\n",
       "18      0           19    22.679618    113,398   464    120,465\n",
       "19      0           20    22.679618    113,398   481    120,778\n",
       "20      0           21    22.679618    113,398   481    120,778\n",
       "21      0           22    22.679618    113,398   481    120,778\n",
       "22      0           23    22.679618    113,398   481    120,778\n",
       "23      0           24    22.679618    113,398   481    120,778\n",
       "24      0           25    22.679618    113,398   478    120,779"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: Repeat with volume-based disruptions\n",
    "\n",
    "Creates a separate directory tree for the volume-based disruptions, and carries out the disruption steps on that set.\n",
    "\n",
    "Set the variable `DO_VOLUME` to `True` to run the following steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_VOLUME = False\n",
    "\n",
    "if DO_VOLUME:\n",
    "\n",
    "    disrupt_type = 'V'\n",
    "    disrupt_steps = 50\n",
    "\n",
    "    resiliency_disruptions.make_disruption_scenarios(disrupt_type, disrupt_steps, scen_path)\n",
    "    resiliency_disruptions.disrupt_network(disrupt_type, disrupt_steps, scen_path, edges_remove)\n",
    "    results = resiliency_disruptions.run_o_steps(disrupt_type, disrupt_steps, scen_path, PYTHON, FTOT)\n",
    "    results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate disruption result report\n",
    "\n",
    "Run `compile_report.py`, which generates the `Disruption_Results.html` report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import compile_report\n",
    "\n",
    "compile_report.render(scen_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:FTOTnetworkEnv] *",
   "language": "python",
   "name": "conda-env-FTOTnetworkEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
