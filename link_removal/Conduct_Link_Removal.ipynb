{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential removal of links and resiliency testing\n",
    "\n",
    "### Overview\n",
    "The notebook iteratively removes the links (edges) in the FTOT road network in order of importance to create distinct disruption scenarios and re-runs FTOT to determine the new optimal solutions and costs.\n",
    "\n",
    "Importance is measured by:\n",
    "\n",
    "- the sum of __betweenness centrality__ of a link's beginning and ending points __OR__   \n",
    "- the __volume__ of background vehicle flows on a link.\n",
    "\n",
    "The notebook outputs (i) CSV files with information on the links removed and scenario results and (ii) interactive HTML report generated with RMarkdown. Note that scenario costs in the outputs are the minimized FTOT objective value, which is based on impeded transport cost, facility build costs, and unmet demand penalties.\n",
    "\n",
    "### Instructions\n",
    "_Important: Before running this notebook, follow instructions the repository's README to (i) set up and activate the Python environment and (ii) run a baseline FTOT scenario._\n",
    "\n",
    "__(1) Update parameters__ in the cell labeled Step 1:  \n",
    "- Baseline scenario name and path  \n",
    "- Measure of importance (volume or betweeness centrality)  \n",
    "- Number of disruption steps  \n",
    "- True/False toggle to export maps for each disruption scenario  \n",
    "     \n",
    "__(2) Run all cells__ by going to the top menu bar > Cell > Run All.\n",
    "\n",
    "__(3) Review outputs__:\n",
    "- [...]\n",
    "- [...]\n",
    "\n",
    "_The notebook may take several hours to run depending on the scenario size and number of disruption steps._\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "- You are working in a Python 3.x environment for this notebook. Refer to the README in this repository for setup instructions.\n",
    "- You have access to a ArcGIS license server if necessary\n",
    "- A baseline FTOT scenario was run with Network Density Reduction (NDR_On set to False in the scenario XML file) and with the swapped ftot_routing.py file from this repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import sqlalchemy\n",
    "import networkx as nx\n",
    "import os\n",
    "import pickle\n",
    "import momepy # for conversion from geopandas GeoDataFrame to networkX Graph\n",
    "import subprocess\n",
    "import shutil\n",
    "import webbrowser\n",
    "import resiliency_disruptions\n",
    "from osgeo import ogr\n",
    "\n",
    "PYTHON = r\"C:\\FTOT\\python3_env\\python.exe\"\n",
    "FTOT = r\"C:\\FTOT\\program\\ftot.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Set User-Defined Parameters (USER INPUT REQUIRED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses Reference Scenario 7 as an example.\n",
    "# Modify `scen_name` and `scen_path` for your scenario.\n",
    "scen_name = 'rs7_capacity'\n",
    "scen_path = r'C:\\FTOT\\scenarios\\reference_scenarios\\rs7_capacity'\n",
    "\n",
    "# Enter disrupt_type 'BC' for betweeness centrality or 'V' for volume \n",
    "# Note: if background flows were not enabled in the baseline scenario,\n",
    "# the notebook will automatically switch to BC.\n",
    "disrupt_type = 'V'\n",
    "\n",
    "# Enter the number of disruption scenarios to generated\n",
    "# Recommend at least 25\n",
    "disrupt_steps = 5 \n",
    "\n",
    "# Set the variable `MAKE_MAPS` to `True` to output maps for each disruption scenario\n",
    "# Note this will increase runtime\n",
    "MAKE_MAPS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Calculate Importance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if disrupt_type == 'BC':\n",
    "    \n",
    "    # Read in prepared betweeness centrality and road network graph data\n",
    "    # If these don't exist, the following steps will create them\n",
    "    picklename = os.path.join(scen_path, 'BetweenessG.pickle')\n",
    "    if os.path.exists(picklename):\n",
    "        file = open(picklename, 'rb')\n",
    "        betweenness_dict_road = pickle.load(file)\n",
    "        G_road = pickle.load(file)\n",
    "    \n",
    "    # Run betweenness centrality on the NetworkX graph\n",
    "    # Note: This step might take several minutes to a few hours   \n",
    "    elif not os.path.exists(picklename):\n",
    "        G_road = resiliency_disruptions.read_gdb(os.path.join(scen_path, 'main.gdb'), 'road')\n",
    "        print('Running Betweenness Centrality calculations. This might take more than 20 minutes.')\n",
    "        betweenness_dict_road = nx.betweenness_centrality(G_road, normalized=False, weight='Length')\n",
    "        print('Completed Betweenness Centrality calculations.')\n",
    "        \n",
    "        # Save with pickle\n",
    "        # Upon load, this pickle will contain the network G_road and the betweenness centrality dict and \n",
    "        with open(picklename, 'wb') as handle:\n",
    "            pickle.dump(betweenness_dict_road, handle)\n",
    "            pickle.dump(G_road, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Associate Importance Metrics with Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in C:\\FTOT\\scenarios\\reference_scenarios\\rs7_capacity\n"
     ]
    }
   ],
   "source": [
    "# Read in FTOT data\n",
    "print('Reading in {}'.format(scen_path))\n",
    "\n",
    "db_name = 'main.db'\n",
    "db_path = 'sqlite:///' + os.path.join(scen_path, db_name)\n",
    "engine = sqlalchemy.create_engine(db_path)\n",
    "\n",
    "table_name = 'networkx_edges'\n",
    "nx_edges = pd.read_sql_table(table_name, engine)\n",
    "\n",
    "table_name = 'networkx_nodes'\n",
    "nx_nodes = pd.read_sql_table(table_name, engine)\n",
    "\n",
    "table_name = 'optimal_variables'\n",
    "optimal_vars = pd.read_sql_table(table_name, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background flows confirmed\n"
     ]
    }
   ],
   "source": [
    "# Check whether scenario has background flow data\n",
    "# volume column in DB is filled with NULL if no\n",
    "# Automatically revert to betweeness centrality if no background flow data\n",
    "# TODO: Confirm want to switch if ANY are null?\n",
    "BACKGROUND_FLOWS = pd.isna(nx_edges['volume']).any()\n",
    "if BACKGROUND_FLOWS:\n",
    "    print('Background flows confirmed')\n",
    "elif disrupt_type == 'V' and not BACKGROUND_FLOWS:\n",
    "    print('WARNING: Network does not have background flows.')\n",
    "    print('Switching importance measure to betweenness centrality.')\n",
    "    disrupt_type = 'BC'\n",
    "else:\n",
    "    print('Scenario does not have background flows. Proceeding with disrupt type BC.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load road network into Graph\n",
    "#G_road_orig_label = resiliency_disruptions.read_gdb(os.path.join(scen_path, 'main.gdb'), 'road')\n",
    "\n",
    "# Get shape_x and shape_y\n",
    "#road_orig_label_nodes = list(G_road_orig_label.nodes)\n",
    "#node_shape_df_road = pd.DataFrame(road_orig_label_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if disrupt_type == 'BC':\n",
    "    \n",
    "    # Get shape_x and shape_y\n",
    "    road_orig_label_nodes = list(G_road.nodes)\n",
    "    node_shape_df_road = pd.DataFrame(road_orig_label_nodes)\n",
    "    \n",
    "    # Make the betweenness_centrality values as the framework to join in shape_x, shape_y, and node_id\n",
    "    bc_df_road = pd.DataFrame.from_dict(betweenness_dict_road, orient = 'index')\n",
    "    bc_df_road = bc_df_road.rename(columns = {0: 'BC'})\n",
    "    \n",
    "    bc_shape_df_road = pd.concat([bc_df_road, node_shape_df_road], axis = 1)\n",
    "    bc_shape_df_road = bc_shape_df_road.rename(columns = {0: 'shape_x', 1: 'shape_y'})\n",
    "    \n",
    "    # Now add node_id from networkx_nodes, using pandas merge with left join\n",
    "    # Use both shape_x and shape_y to identify the nodes correctly\n",
    "\n",
    "    bc_node_df = pd.merge(bc_shape_df_road, nx_nodes, on = ['shape_x', 'shape_y'], how = 'left')\n",
    "    \n",
    "    # Now use this dataframe to populate a dataframe of edges\n",
    "    # We will want the following from networkx_edges:\n",
    "    # edge_id, from_node_id, to_node_id, mode_source, miles, mode_source_oid\n",
    "    # Then using the node_id column in the new bc_node_df, add these:\n",
    "    # from_node_BC, to_node_BC\n",
    "    # and sum those for sum_node_BC\n",
    "    # TODO: can likely skip this step if using 'V' not 'BC'\n",
    "    merge_from = pd.merge(nx_edges, bc_node_df[['BC', 'node_id']],\n",
    "                          left_on = 'from_node_id',\n",
    "                          right_on = 'node_id',\n",
    "                          how = 'left')\n",
    "    merge_from = merge_from.rename(columns = {'BC': 'from_node_BC'})\n",
    "\n",
    "    merge_to = pd.merge(merge_from, bc_node_df[['BC', 'node_id']],\n",
    "                        left_on = 'to_node_id',\n",
    "                        right_on = 'node_id',\n",
    "                        how = 'left')\n",
    "    merge_to = merge_to.rename(columns = {'BC': 'to_node_BC'})\n",
    "\n",
    "    # Sum the BC values\n",
    "\n",
    "    merge_to['sum_BC'] = merge_to.filter(like = \"node_BC\").sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if disrupt_type == 'V':\n",
    "    merge_to = nx_edges.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edge_id</th>\n",
       "      <th>from_node_id</th>\n",
       "      <th>to_node_id</th>\n",
       "      <th>artificial</th>\n",
       "      <th>mode_source</th>\n",
       "      <th>mode_source_oid</th>\n",
       "      <th>length</th>\n",
       "      <th>route_cost_scaling</th>\n",
       "      <th>capacity</th>\n",
       "      <th>volume</th>\n",
       "      <th>...</th>\n",
       "      <th>urban</th>\n",
       "      <th>limited_access</th>\n",
       "      <th>variable_type</th>\n",
       "      <th>var_id</th>\n",
       "      <th>variable_value</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>nx_edge_id</th>\n",
       "      <th>mode_oid</th>\n",
       "      <th>converted_capacity</th>\n",
       "      <th>converted_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>332</td>\n",
       "      <td>1887</td>\n",
       "      <td>2</td>\n",
       "      <td>road</td>\n",
       "      <td>282</td>\n",
       "      <td>3.541860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>399</td>\n",
       "      <td>1888</td>\n",
       "      <td>2</td>\n",
       "      <td>road</td>\n",
       "      <td>349</td>\n",
       "      <td>0.275609</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>438</td>\n",
       "      <td>1889</td>\n",
       "      <td>2</td>\n",
       "      <td>road</td>\n",
       "      <td>388</td>\n",
       "      <td>0.087752</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>448</td>\n",
       "      <td>1890</td>\n",
       "      <td>2</td>\n",
       "      <td>road</td>\n",
       "      <td>398</td>\n",
       "      <td>0.129394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>452</td>\n",
       "      <td>1891</td>\n",
       "      <td>2</td>\n",
       "      <td>road</td>\n",
       "      <td>402</td>\n",
       "      <td>0.238547</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   edge_id  from_node_id  to_node_id  artificial mode_source  mode_source_oid  \\\n",
       "0        1           332        1887           2        road              282   \n",
       "1        2           399        1888           2        road              349   \n",
       "2        3           438        1889           2        road              388   \n",
       "3        4           448        1890           2        road              398   \n",
       "4        5           452        1891           2        road              402   \n",
       "\n",
       "     length  route_cost_scaling  capacity  volume  ...   urban  \\\n",
       "0  3.541860                 1.0       NaN     NaN  ... -9999.0   \n",
       "1  0.275609                 1.0       NaN     NaN  ... -9999.0   \n",
       "2  0.087752                 1.0       NaN     NaN  ... -9999.0   \n",
       "3  0.129394                 1.0       NaN     NaN  ... -9999.0   \n",
       "4  0.238547                 1.0       NaN     NaN  ... -9999.0   \n",
       "\n",
       "   limited_access  variable_type var_id  variable_value  variable_name  \\\n",
       "0         -9999.0            NaN    NaN             NaN            NaN   \n",
       "1         -9999.0            NaN    NaN             NaN            NaN   \n",
       "2         -9999.0            NaN    NaN             NaN            NaN   \n",
       "3         -9999.0            NaN    NaN             NaN            NaN   \n",
       "4         -9999.0            NaN    NaN             NaN            NaN   \n",
       "\n",
       "  nx_edge_id  mode_oid  converted_capacity  converted_volume  \n",
       "0        NaN       NaN                 NaN               NaN  \n",
       "1        NaN       NaN                 NaN               NaN  \n",
       "2        NaN       NaN                 NaN               NaN  \n",
       "3        NaN       NaN                 NaN               NaN  \n",
       "4        NaN       NaN                 NaN               NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select optimal_vars DB columns to keep \n",
    "use_opt_vars = ['variable_type',\n",
    "               'var_id',\n",
    "               'variable_value',\n",
    "                'variable_name',\n",
    "                'nx_edge_id',\n",
    "                'mode_oid',\n",
    "                'converted_capacity',\n",
    "                'converted_volume'\n",
    "               ]\n",
    "\n",
    "merge_opt = pd.merge(merge_to, optimal_vars[use_opt_vars],\n",
    "                     left_on = 'edge_id',\n",
    "                     right_on = 'nx_edge_id',\n",
    "                     how = 'left')\n",
    "\n",
    "merge_opt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>edge_id</th>\n",
       "      <th>from_node_id</th>\n",
       "      <th>to_node_id</th>\n",
       "      <th>length</th>\n",
       "      <th>capacity</th>\n",
       "      <th>volume</th>\n",
       "      <th>variable_type</th>\n",
       "      <th>variable_value</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>nx_edge_id</th>\n",
       "      <th>mode_oid</th>\n",
       "      <th>converted_capacity</th>\n",
       "      <th>converted_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5482</td>\n",
       "      <td>5483</td>\n",
       "      <td>4141</td>\n",
       "      <td>7187</td>\n",
       "      <td>0.071771</td>\n",
       "      <td>69446.587921</td>\n",
       "      <td>47941.5</td>\n",
       "      <td>Edge</td>\n",
       "      <td>22679.618</td>\n",
       "      <td>Edge_10974</td>\n",
       "      <td>5483.0</td>\n",
       "      <td>249096.0</td>\n",
       "      <td>1.666718e+06</td>\n",
       "      <td>1150596.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3029</td>\n",
       "      <td>3030</td>\n",
       "      <td>3094</td>\n",
       "      <td>3643</td>\n",
       "      <td>0.318439</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>41687.0</td>\n",
       "      <td>Edge</td>\n",
       "      <td>75443.128</td>\n",
       "      <td>Edge_6067</td>\n",
       "      <td>3030.0</td>\n",
       "      <td>80088.0</td>\n",
       "      <td>1.080000e+06</td>\n",
       "      <td>1000488.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12538</td>\n",
       "      <td>12539</td>\n",
       "      <td>7167</td>\n",
       "      <td>1898</td>\n",
       "      <td>0.031103</td>\n",
       "      <td>47745.379525</td>\n",
       "      <td>40784.0</td>\n",
       "      <td>Edge</td>\n",
       "      <td>43134.521</td>\n",
       "      <td>Edge_25085</td>\n",
       "      <td>12539.0</td>\n",
       "      <td>249072.0</td>\n",
       "      <td>1.145889e+06</td>\n",
       "      <td>978816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>61</td>\n",
       "      <td>1898</td>\n",
       "      <td>7194</td>\n",
       "      <td>0.828394</td>\n",
       "      <td>47745.379525</td>\n",
       "      <td>40784.0</td>\n",
       "      <td>Edge</td>\n",
       "      <td>43134.521</td>\n",
       "      <td>Edge_129</td>\n",
       "      <td>61.0</td>\n",
       "      <td>249518.0</td>\n",
       "      <td>1.145889e+06</td>\n",
       "      <td>978816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14861</td>\n",
       "      <td>14862</td>\n",
       "      <td>8218</td>\n",
       "      <td>8215</td>\n",
       "      <td>1.454485</td>\n",
       "      <td>47739.607172</td>\n",
       "      <td>38842.5</td>\n",
       "      <td>Edge</td>\n",
       "      <td>43134.521</td>\n",
       "      <td>Edge_29731</td>\n",
       "      <td>14862.0</td>\n",
       "      <td>270845.0</td>\n",
       "      <td>1.145751e+06</td>\n",
       "      <td>932220.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  edge_id  from_node_id  to_node_id    length      capacity   volume  \\\n",
       "0   5482     5483          4141        7187  0.071771  69446.587921  47941.5   \n",
       "1   3029     3030          3094        3643  0.318439  45000.000000  41687.0   \n",
       "2  12538    12539          7167        1898  0.031103  47745.379525  40784.0   \n",
       "3     60       61          1898        7194  0.828394  47745.379525  40784.0   \n",
       "4  14861    14862          8218        8215  1.454485  47739.607172  38842.5   \n",
       "\n",
       "  variable_type  variable_value variable_name  nx_edge_id  mode_oid  \\\n",
       "0          Edge       22679.618    Edge_10974      5483.0  249096.0   \n",
       "1          Edge       75443.128     Edge_6067      3030.0   80088.0   \n",
       "2          Edge       43134.521    Edge_25085     12539.0  249072.0   \n",
       "3          Edge       43134.521      Edge_129        61.0  249518.0   \n",
       "4          Edge       43134.521    Edge_29731     14862.0  270845.0   \n",
       "\n",
       "   converted_capacity  converted_volume  \n",
       "0        1.666718e+06         1150596.0  \n",
       "1        1.080000e+06         1000488.0  \n",
       "2        1.145889e+06          978816.0  \n",
       "3        1.145889e+06          978816.0  \n",
       "4        1.145751e+06          932220.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create ranked lists of edges to remove\n",
    "# (1) Keep only edges in the optimal solution\n",
    "# (2) Sort by sum_BC or volume\n",
    "# (3) Keep the columns we need\n",
    "# (4) Reset the index to assign rank\n",
    "\n",
    "# Note: in resiliency_disruptions.disrupt_network, the edges_remove DataFrame is sorted again by 'V' or 'BC'\n",
    "\n",
    "use_cols = ['edge_id', 'from_node_id', 'to_node_id', 'length', 'capacity', 'volume', 'sum_BC',\n",
    "            'variable_type', 'variable_value', 'variable_name', 'nx_edge_id', 'mode_oid', 'converted_capacity',\n",
    "            'converted_volume']\n",
    "\n",
    "if disrupt_type == 'V':\n",
    "    edges_remove = merge_opt[merge_opt['variable_value'] > 0].sort_values(by = 'volume', ascending = False).filter(items = use_cols).reset_index()\n",
    "elif disrupt_type == 'BC':\n",
    "    edges_remove = merge_opt[merge_opt['variable_value'] > 0].sort_values(by = 'sum_BC', ascending = False).filter(items = use_cols).reset_index()\n",
    "\n",
    "edges_remove.to_csv(os.path.join(scen_path, 'Edges_to_Remove.csv'), index = False)\n",
    "\n",
    "edges_remove.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Scenarios, Disrupt Edges, and Run FTOT\n",
    "\n",
    "Create disrupted network by copying everything in `scen_path` to a new directory. Then overwrite the `networkx_edges` tables in that main.db with the disrupted versions.\n",
    "\n",
    "##### Assumptions:\n",
    "\n",
    "  1. ArcGIS Pro is installed.\n",
    "  2. The FTOT version being used has been modified according to the `README` in this directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 5 scenarios based on rs7_capacity\n",
      "Disrupted 5 scenarios\n"
     ]
    }
   ],
   "source": [
    "# Make new scenarios\n",
    "resiliency_disruptions.make_disruption_scenarios(disrupt_type, disrupt_steps, scen_path)\n",
    "\n",
    "# Apply disruption\n",
    "resiliency_disruptions.disrupt_network(disrupt_type, disrupt_steps, scen_path, edges_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running o1 for disrupt01\n",
      "Running o2 for disrupt01\n",
      "Running p for disrupt01\n",
      "Running d for disrupt01\n",
      "Preparing to search over o2_log_2024_04_12_15-03-05.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           01            0          0   497      2,412\n",
      "Running o1 for disrupt02\n",
      "Running o2 for disrupt02\n",
      "Running p for disrupt02\n",
      "Running d for disrupt02\n",
      "Preparing to search over o2_log_2024_04_12_15-06-17.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           02            0          0   493      2,414\n",
      "Running o1 for disrupt03\n",
      "Running o2 for disrupt03\n",
      "Running p for disrupt03\n",
      "Running d for disrupt03\n",
      "Preparing to search over o2_log_2024_04_12_15-09-29.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           03            0          0   488      2,414\n",
      "Running o1 for disrupt04\n",
      "Running o2 for disrupt04\n",
      "Running p for disrupt04\n",
      "Running d for disrupt04\n",
      "Preparing to search over o2_log_2024_04_12_15-12-51.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           04            0          0   488      2,414\n",
      "Running o1 for disrupt05\n",
      "Running o2 for disrupt05\n",
      "Running p for disrupt05\n",
      "Running d for disrupt05\n",
      "Preparing to search over o2_log_2024_04_12_15-15-57.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           05            0          0   494      2,427\n"
     ]
    }
   ],
   "source": [
    "# Begin running O through M steps of FTOT on the disupted scenarios\n",
    "# This may take several hours, depending on size of the network and number of disruption scenarios\n",
    "results = resiliency_disruptions.run_o_steps(disrupt_type, disrupt_steps, scen_path, PYTHON, FTOT, MAKE_MAPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate Disruption Result Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: bug in the handoff here\n",
    "R_Process = subprocess.Popen(['Rscript.exe', 'compile_report.R', scen_path, str(BACKGROUND_FLOWS), disrupt_type],\n",
    "                 stdout = subprocess.PIPE, stderr = subprocess.PIPE)\n",
    "\n",
    "here = os.getcwd()\n",
    "\n",
    "# move rendered HTML file when complete to scen_path, will replace any existing file\n",
    "if not os.path.exists(os.path.join(here, 'Disruption_Results.html')):\n",
    "    print(\"OUTPUT FILE ERROR: Disruption_Results.html could not be found\")\n",
    "    raise Exception(\"OUTPUT FILE ERROR: Disruption_Results.html could not be found\")\n",
    "shutil.move(os.path.join(here, 'Disruption_Results.html'), os.path.join(scen_path, 'Disruption_Results_' +\n",
    "                                                                    http://localhost:8888/notebooks/github/FTOT-Resilience-Link_Removal/link_removal/Conduct_Link_Removal.ipynb#    disrupt_type + '_' + str(disrupt_steps) +\n",
    "                                                                        '.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webbrowser.open('file://' + os.path.realpath(os.path.join(scen_path, 'Disruption_Results_' + disrupt_type +\n",
    "                                                          '_' + str(disrupt_steps) + '.html')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
