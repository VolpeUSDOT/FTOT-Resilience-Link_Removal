{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential removal of links and resiliency testing\n",
    "\n",
    "- Disruption of a network by removal of links, based on:\n",
    "    + Sum of betweenness centrality of from and to nodes\n",
    "    + Volume of commodity flow\n",
    "- Calculation of performance in terms of cost and unmet demand by re-running disrupted network. \n",
    "- Plot link removal along x-axis and performance on y-axis, comparing networks of differing evenness. Dynamic report generated in an RMarkdown automatically from this Notebook.\n",
    "\n",
    "**Assumptions**\n",
    "\n",
    "- Working in a Python 3.x environment for this notebook\n",
    "    + Refer to the README in this repository for instructions on setup of all dependencies with `conda`\n",
    "- Access to ArcGIS license server if necessary\n",
    "- FTOT scenario was run with Network Density Reduction (NDR) off\n",
    "    + NDR_On should be False in the scenario XML file\n",
    "\n",
    "*Reference*\n",
    "\n",
    "- [NetworkX Documentation](https://networkx.github.io/documentation/stable/tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import sqlalchemy\n",
    "import networkx as nx\n",
    "import os\n",
    "import pickle\n",
    "import momepy # for conversion from geopandas GeoDataFrame to networkX Graph\n",
    "import subprocess\n",
    "import shutil\n",
    "import webbrowser\n",
    "import resiliency_disruptions\n",
    "\n",
    "# Uses Reference Scenario 7 as an example. Modify `scen_name` and `scen_path` for your scenario.\n",
    "scen_name = 'rs7_capacity'\n",
    "scen_path = r'C:\\FTOT\\scenarios\\reference_scenarios\\rs7_capacity'\n",
    "\n",
    "# TODO: use GDB instead for the road network layer\n",
    "shp_path = os.path.join(scen_path, 'temp_networkx_shp_files')\n",
    "\n",
    "picklename = os.path.join(scen_path, 'BetweenessG.pickle')\n",
    "\n",
    "# TODO: Set to true if base scenario has background flows set to true in the scenario XML\n",
    "BACKGROUND_FLOWS = False\n",
    "\n",
    "# TODO: may not require this anymore though another code change is decreasing buffer from 100 to 50 miles\n",
    "if not os.path.exists(shp_path):\n",
    "    print('Please modify the FTOT code using the `ftot_networkx.py` and `ftot_routing.py` scripts in this repository and run the scenario again.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in prepared betweeness centrality and road network graph data\n",
    "# If these don't exist, the following steps will create them\n",
    "if os.path.exists(picklename):\n",
    "    file = open(picklename, 'rb')\n",
    "    betweenness_dict_road = pickle.load(file)\n",
    "    G_road = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by using betweenness centrality calculation using networkX\n",
    "if not os.path.exists(picklename):\n",
    "    # TODO: replace use of geopandas with ogr from osgeo which is already in this environment (see read_gdb method in FTOT as an example)\n",
    "    road = gpd.read_file(os.path.join(shp_path, 'road.shp'))\n",
    "    \n",
    "    # convert from geodataframe to Graph for networkX\n",
    "    G_road = momepy.gdf_to_nx(road, approach='primal')\n",
    "    \n",
    "    # Process the networkX graph\n",
    "    G_road = nx.convert_node_labels_to_integers(G_road, first_label=0, ordering='default', label_attribute=\"xy_coord_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run betweenness centrality on the NetworkX graph\n",
    "# Note: This step might take several minutes to a few hours\n",
    "# Run if pickle not available\n",
    "# TODO: can likely skip this step if running 'V' not 'BC' but then do not have betweenness_dict_road variable\n",
    "if not os.path.exists(picklename):\n",
    "    print('Running Betweenness Centrality calculations. This might take more than 20 minutes.')\n",
    "    betweenness_dict_road = nx.betweenness_centrality(G_road, normalized=False, weight='Length')\n",
    "    print('Completed Betweenness Centrality calculations.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save with pickle\n",
    "# On load, need to know that there are two objects in this pickle, the betweenness centrality dict and the network G\n",
    "if not os.path.exists(picklename):\n",
    "    with open(picklename, 'wb') as handle:\n",
    "        pickle.dump(betweenness_dict_road, handle)\n",
    "        pickle.dump(G_road, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Betweenness Centrality calculations to edges\n",
    "\n",
    "- Sum BC for each node of a link\n",
    "- Create data frame for repeated link removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\FTOT\\scenarios\\reference_scenarios\\rs7_capacity\n"
     ]
    }
   ],
   "source": [
    "# Read in FTOT data\n",
    "print(scen_path)\n",
    "db_name = 'main.db'\n",
    "\n",
    "db_path = 'sqlite:///' + os.path.join(scen_path, db_name)\n",
    "\n",
    "engine = sqlalchemy.create_engine(db_path)\n",
    "\n",
    "table_name = 'networkx_edges'\n",
    "nx_edges = pd.read_sql_table(table_name, engine)\n",
    "\n",
    "# TODO: bring in additional metrics (route_cost, transport_cost, route_cost_transport, co2_cost) from networkx_edge_costs table\n",
    "\n",
    "table_name = 'networkx_nodes'\n",
    "nx_nodes = pd.read_sql_table(table_name, engine)\n",
    "\n",
    "table_name = 'optimal_variables'\n",
    "optimal_vars = pd.read_sql_table(table_name, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_type</th>\n",
       "      <th>var_id</th>\n",
       "      <th>variable_value</th>\n",
       "      <th>converted_capacity</th>\n",
       "      <th>converted_volume</th>\n",
       "      <th>converted_capac_minus_volume</th>\n",
       "      <th>edge_type</th>\n",
       "      <th>commodity_name</th>\n",
       "      <th>o_facility</th>\n",
       "      <th>d_facility</th>\n",
       "      <th>...</th>\n",
       "      <th>units</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>nx_edge_id</th>\n",
       "      <th>mode</th>\n",
       "      <th>mode_oid</th>\n",
       "      <th>length</th>\n",
       "      <th>original_facility</th>\n",
       "      <th>final_facility</th>\n",
       "      <th>prior_edge</th>\n",
       "      <th>distance_travelled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Edge</td>\n",
       "      <td>1</td>\n",
       "      <td>181436.9500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>connector</td>\n",
       "      <td>freight_bulk</td>\n",
       "      <td>rmp_25017</td>\n",
       "      <td>rmp_25017</td>\n",
       "      <td>...</td>\n",
       "      <td>metric_ton</td>\n",
       "      <td>Edge_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Edge</td>\n",
       "      <td>2</td>\n",
       "      <td>9071.8474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>connector</td>\n",
       "      <td>freight_parcel</td>\n",
       "      <td>dest_25005</td>\n",
       "      <td>dest_25005</td>\n",
       "      <td>...</td>\n",
       "      <td>metric_ton</td>\n",
       "      <td>Edge_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Edge</td>\n",
       "      <td>3</td>\n",
       "      <td>22679.6180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>connector</td>\n",
       "      <td>freight_parcel</td>\n",
       "      <td>dest_25009</td>\n",
       "      <td>dest_25009</td>\n",
       "      <td>...</td>\n",
       "      <td>metric_ton</td>\n",
       "      <td>Edge_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Edge</td>\n",
       "      <td>4</td>\n",
       "      <td>68038.8560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>connector</td>\n",
       "      <td>freight_parcel</td>\n",
       "      <td>dest_25021</td>\n",
       "      <td>dest_25021</td>\n",
       "      <td>...</td>\n",
       "      <td>metric_ton</td>\n",
       "      <td>Edge_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edge</td>\n",
       "      <td>5</td>\n",
       "      <td>22679.6180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>connector</td>\n",
       "      <td>freight_parcel</td>\n",
       "      <td>dest_25023</td>\n",
       "      <td>dest_25023</td>\n",
       "      <td>...</td>\n",
       "      <td>metric_ton</td>\n",
       "      <td>Edge_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>Edge</td>\n",
       "      <td>34075</td>\n",
       "      <td>58967.0080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transport</td>\n",
       "      <td>freight_parcel</td>\n",
       "      <td>None</td>\n",
       "      <td>dest_25027</td>\n",
       "      <td>...</td>\n",
       "      <td>metric_ton</td>\n",
       "      <td>Edge_34075</td>\n",
       "      <td>17043.0</td>\n",
       "      <td>road</td>\n",
       "      <td>311232.0</td>\n",
       "      <td>0.036034</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Edge</td>\n",
       "      <td>34081</td>\n",
       "      <td>58967.0080</td>\n",
       "      <td>704385.369727</td>\n",
       "      <td>312744.0</td>\n",
       "      <td>391641.369727</td>\n",
       "      <td>transport</td>\n",
       "      <td>freight_parcel</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>metric_ton</td>\n",
       "      <td>Edge_34081</td>\n",
       "      <td>17046.0</td>\n",
       "      <td>road</td>\n",
       "      <td>311217.0</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>Edge</td>\n",
       "      <td>34083</td>\n",
       "      <td>81646.6270</td>\n",
       "      <td>728794.816589</td>\n",
       "      <td>206676.0</td>\n",
       "      <td>522118.816589</td>\n",
       "      <td>transport</td>\n",
       "      <td>freight_parcel</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>metric_ton</td>\n",
       "      <td>Edge_34083</td>\n",
       "      <td>17047.0</td>\n",
       "      <td>road</td>\n",
       "      <td>311220.0</td>\n",
       "      <td>0.075613</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Edge</td>\n",
       "      <td>34084</td>\n",
       "      <td>181436.9500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transport</td>\n",
       "      <td>freight_bulk</td>\n",
       "      <td>None</td>\n",
       "      <td>proc_25025</td>\n",
       "      <td>...</td>\n",
       "      <td>metric_ton</td>\n",
       "      <td>Edge_34084</td>\n",
       "      <td>17048.0</td>\n",
       "      <td>road</td>\n",
       "      <td>311234.0</td>\n",
       "      <td>0.239426</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Edge</td>\n",
       "      <td>34086</td>\n",
       "      <td>99790.3210</td>\n",
       "      <td>728794.816589</td>\n",
       "      <td>206676.0</td>\n",
       "      <td>522118.816589</td>\n",
       "      <td>transport</td>\n",
       "      <td>freight_parcel</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>metric_ton</td>\n",
       "      <td>Edge_34086</td>\n",
       "      <td>17049.0</td>\n",
       "      <td>road</td>\n",
       "      <td>311219.0</td>\n",
       "      <td>0.217271</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>497 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    variable_type  var_id  variable_value  converted_capacity  \\\n",
       "0            Edge       1     181436.9500                 NaN   \n",
       "1            Edge       2       9071.8474                 NaN   \n",
       "2            Edge       3      22679.6180                 NaN   \n",
       "3            Edge       4      68038.8560                 NaN   \n",
       "4            Edge       5      22679.6180                 NaN   \n",
       "..            ...     ...             ...                 ...   \n",
       "492          Edge   34075      58967.0080                 NaN   \n",
       "493          Edge   34081      58967.0080       704385.369727   \n",
       "494          Edge   34083      81646.6270       728794.816589   \n",
       "495          Edge   34084     181436.9500                 NaN   \n",
       "496          Edge   34086      99790.3210       728794.816589   \n",
       "\n",
       "     converted_volume  converted_capac_minus_volume  edge_type  \\\n",
       "0                 NaN                           NaN  connector   \n",
       "1                 NaN                           NaN  connector   \n",
       "2                 NaN                           NaN  connector   \n",
       "3                 NaN                           NaN  connector   \n",
       "4                 NaN                           NaN  connector   \n",
       "..                ...                           ...        ...   \n",
       "492               0.0                           NaN  transport   \n",
       "493          312744.0                 391641.369727  transport   \n",
       "494          206676.0                 522118.816589  transport   \n",
       "495               0.0                           NaN  transport   \n",
       "496          206676.0                 522118.816589  transport   \n",
       "\n",
       "     commodity_name  o_facility  d_facility  ...       units  variable_name  \\\n",
       "0      freight_bulk   rmp_25017   rmp_25017  ...  metric_ton         Edge_1   \n",
       "1    freight_parcel  dest_25005  dest_25005  ...  metric_ton         Edge_2   \n",
       "2    freight_parcel  dest_25009  dest_25009  ...  metric_ton         Edge_3   \n",
       "3    freight_parcel  dest_25021  dest_25021  ...  metric_ton         Edge_4   \n",
       "4    freight_parcel  dest_25023  dest_25023  ...  metric_ton         Edge_5   \n",
       "..              ...         ...         ...  ...         ...            ...   \n",
       "492  freight_parcel        None  dest_25027  ...  metric_ton     Edge_34075   \n",
       "493  freight_parcel        None        None  ...  metric_ton     Edge_34081   \n",
       "494  freight_parcel        None        None  ...  metric_ton     Edge_34083   \n",
       "495    freight_bulk        None  proc_25025  ...  metric_ton     Edge_34084   \n",
       "496  freight_parcel        None        None  ...  metric_ton     Edge_34086   \n",
       "\n",
       "     nx_edge_id  mode  mode_oid    length  original_facility final_facility  \\\n",
       "0           NaN  None       NaN       NaN               None           None   \n",
       "1           NaN  None       NaN       NaN               None           None   \n",
       "2           NaN  None       NaN       NaN               None           None   \n",
       "3           NaN  None       NaN       NaN               None           None   \n",
       "4           NaN  None       NaN       NaN               None           None   \n",
       "..          ...   ...       ...       ...                ...            ...   \n",
       "492     17043.0  road  311232.0  0.036034               None           None   \n",
       "493     17046.0  road  311217.0  0.000161               None           None   \n",
       "494     17047.0  road  311220.0  0.075613               None           None   \n",
       "495     17048.0  road  311234.0  0.239426               None           None   \n",
       "496     17049.0  road  311219.0  0.217271               None           None   \n",
       "\n",
       "    prior_edge distance_travelled  \n",
       "0         None               None  \n",
       "1         None               None  \n",
       "2         None               None  \n",
       "3         None               None  \n",
       "4         None               None  \n",
       "..         ...                ...  \n",
       "492       None               None  \n",
       "493       None               None  \n",
       "494       None               None  \n",
       "495       None               None  \n",
       "496       None               None  \n",
       "\n",
       "[497 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: replace use of geopandas with ogr from osgeo which is already in this environment (see read_gdb method in FTOT as an example)\n",
    "road_orig_label = gpd.read_file(os.path.join(shp_path, 'road.shp'))\n",
    "# convert from geodataframe to Graph for networkX\n",
    "G_road_orig_label = momepy.gdf_to_nx(road_orig_label, approach='primal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_orig_label_nodes = list(G_road_orig_label.nodes) # these values are the shape_x and shape_y values in `networkx_nodes` \n",
    "# Use that to get node_id from networkx_edges in the database\n",
    "# Then use those id values to get edges info\n",
    "# Then line up the new integer labels with this list of ids to get betweenness centrality for each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the betweenness_centrality values as the framework to join in shape_x, shape_y, and node_id\n",
    "# TODO: can likely skip this step if using 'V' not 'BC'\n",
    "bc_df_road = pd.DataFrame.from_dict(betweenness_dict_road, orient = 'index')\n",
    "bc_df_road = bc_df_road.rename(columns = {0: 'BC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_shape_df_road = pd.DataFrame(road_orig_label_nodes)\n",
    "\n",
    "# TODO: can likely skip this step if using 'V' not 'BC' but may complicate things if missing shape_x and shape_y\n",
    "bc_shape_df_road = pd.concat([bc_df_road, node_shape_df_road], axis = 1)\n",
    "bc_shape_df_road = bc_shape_df_road.rename(columns = {0: 'shape_x', 1: 'shape_y'})\n",
    "\n",
    "# Now add node_id from networkx_nodes, using pandas merge with left join\n",
    "# Use both shape_x and shape_y to identify the nodes correctly\n",
    "\n",
    "bc_node_df = pd.merge(bc_shape_df_road, nx_nodes, on = ['shape_x', 'shape_y'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use this dataframe to populate a dataframe of edges\n",
    "# We will want the following from networkx_edges:\n",
    "# edge_id, from_node_id, to_node_id, mode_source, miles, mode_source_oid\n",
    "# Then using the node_id column in the new bc_node_df, add these:\n",
    "# from_node_BC, to_node_BC\n",
    "# and sum those for sum_node_BC\n",
    "# TODO: can likely skip this step if using 'V' not 'BC'\n",
    "merge_from = pd.merge(nx_edges, bc_node_df[['BC', 'node_id']],\n",
    "                      left_on = 'from_node_id',\n",
    "                      right_on = 'node_id',\n",
    "                      how = 'left')\n",
    "merge_from = merge_from.rename(columns = {'BC': 'from_node_BC'})\n",
    "\n",
    "merge_to = pd.merge(merge_from, bc_node_df[['BC', 'node_id']],\n",
    "                    left_on = 'to_node_id',\n",
    "                    right_on = 'node_id',\n",
    "                    how = 'left')\n",
    "merge_to = merge_to.rename(columns = {'BC': 'to_node_BC'})\n",
    "\n",
    "# Sum the BC values\n",
    "\n",
    "merge_to['sum_BC'] = merge_to.filter(like = \"node_BC\").sum(axis = 1)\n",
    "\n",
    "# Then from optimal_variables, get variable_name, nc_edge_id, mode, mode_oid, miles,\n",
    "# variable_value, converted_capacity, and converted_volume\n",
    "\n",
    "use_opt_vars = ['variable_type',\n",
    "               'var_id',\n",
    "               'variable_value',\n",
    "                'variable_name',\n",
    "                'nx_edge_id',\n",
    "                'mode_oid',\n",
    "                'converted_capacity',\n",
    "                'converted_volume'\n",
    "               ]\n",
    "\n",
    "merge_opt = pd.merge(merge_to, optimal_vars[use_opt_vars],\n",
    "                     left_on = 'edge_id',\n",
    "                     right_on = 'nx_edge_id',\n",
    "                     how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_vars[use_opt_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_opt.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ranked lists of edges to remove\n",
    "# First, keep only edges in the optimal solution\n",
    "# Then rank by sum_BC\n",
    "# Then just keep the columns we need, and reset the index\n",
    "# Note: in resiliency_disruptions.disrupt_network, the edges_remove DataFrame is sorted again by 'V' or 'BC'\n",
    "# TODO: update use_cols as needed for additional metrics\n",
    "use_cols = ['edge_id', 'from_node_id', 'to_node_id', 'length', 'capacity', 'volume', 'sum_BC',\n",
    "            'variable_type', 'variable_value', 'variable_name', 'nx_edge_id', 'mode_oid', 'converted_capacity',\n",
    "            'converted_volume']\n",
    "\n",
    "# TODO: if 'V', we may not have sum_BC column at this point\n",
    "# TODO: note that sort_values (both here and in resiliency_disruptions.disrupt_network) does not break ties (significant for 'V')\n",
    "edges_remove = merge_opt[merge_opt['variable_value'] > 0].sort_values(by = 'sum_BC', ascending = False).filter(items = use_cols).reset_index()\n",
    "\n",
    "edges_remove.to_csv(os.path.join(scen_path, 'Edges_to_Remove.csv'),\n",
    "                    index = False)\n",
    "\n",
    "edges_remove.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Scenarios, Disrupt, Run FTOT\n",
    "\n",
    "Create disrupted network by copying everything in `scen_path` to a new directory.\n",
    "\n",
    "Then overwrite the `networkx_edges` tables in that main.db with the disrupted versions.\n",
    "\n",
    "##### Assumptions:\n",
    "\n",
    "  1. ArcGIS with 64-bit geoprocessing is installed.\n",
    "  2. The FTOT version being used has been modified according to the `README` in this directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "disrupt_type = 'BC' # Can disrupt based on betweenness centrality, 'BC', or volume, 'V'\n",
    "disrupt_steps = 12  # This is the number of steps to use. Recommend at least 25.\n",
    "\n",
    "resiliency_disruptions.make_disruption_scenarios(disrupt_type, disrupt_steps, scen_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resiliency_disruptions.disrupt_network(disrupt_type, disrupt_steps, scen_path, edges_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: move these higher up in the notebook\n",
    "PYTHON = r\"C:\\FTOT\\python3_env\\python.exe\"\n",
    "repo_location = %pwd\n",
    "repo_location = os.path.split(repo_location)[0]\n",
    "FTOT = r\"C:\\FTOT\\program\\ftot.py\"  # Optionally: os.path.join(repo_location, 'program', 'ftot.py')\n",
    "print(FTOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin running O through M steps of FTOT on the disupted scenarios\n",
    "# This may take several hours, depending on size of the network and number of steps\n",
    "\n",
    "results = resiliency_disruptions.run_o_steps(disrupt_type, disrupt_steps, scen_path, PYTHON, FTOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: Repeat with volume-based disruptions\n",
    "\n",
    "Creates a separate directory tree for the volume-based disruptions and carries out the disruption steps on that set.\n",
    "\n",
    "Set the variable `DO_VOLUME` to `True` to run the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_VOLUME = True\n",
    "\n",
    "if DO_VOLUME:\n",
    "\n",
    "    disrupt_type = 'V'\n",
    "    disrupt_steps = 5\n",
    "\n",
    "    resiliency_disruptions.make_disruption_scenarios(disrupt_type, disrupt_steps, scen_path)\n",
    "    resiliency_disruptions.disrupt_network(disrupt_type, disrupt_steps, scen_path, edges_remove)\n",
    "    results = resiliency_disruptions.run_o_steps(disrupt_type, disrupt_steps, scen_path, PYTHON, FTOT)\n",
    "    results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate disruption result report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: bug in the handoff here, but not reported out to the user... looks like it succeeded but it did not\n",
    "# TODO: hand in the disrupt_type parameter as well (right now, hard-coded in RMarkdown as BC)\n",
    "R_process = subprocess.Popen(['Rscript.exe', 'compile_report.R', scen_path, BACKGROUND_FLOWS, DO_VOLUME,],\n",
    "                             stdout = subprocess.PIPE, stderr = subprocess.PIPE)\n",
    "\n",
    "here = os.getcwd()\n",
    "webbrowser.open('file://' + os.path.realpath(os.path.join(here, 'Disruption_Results.html')))\n",
    "\n",
    "# TODO: move html file to scen_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.realpath(os.path.join(here, 'Disruption_Results.html'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
